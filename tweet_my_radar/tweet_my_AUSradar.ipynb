{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use the Twitter API and Py-ART to Tweet Your Australian Radar!\n",
    "----------------------------------------------------------\n",
    "\n",
    "*Scott Collis, Argonne National Laboratory* Adapted for Australian radars by Joshua Soderholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meso/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py:43: DeprecationWarning: IPythonKernel._eventloop_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _eventloop_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "#First some imports\n",
    "import twitter #https://python-twitter.readthedocs.io/en/latest/index.html\n",
    "import json\n",
    "import pyart #https://github.com/ARM-DOE/pyart\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from owslib.wms import WebMapService\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from boto.s3.connection import S3Connection #Anaconda installable\n",
    "import shutil, os\n",
    "from datetime import timedelta, datetime\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import shutil, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some functions to deal with Amazon Web Services Simple Storage Service (s3) holding of BOM radar archive. This is a realtime and historical archive provided by Fugro-ROAMES for testing purposes. Future aim is to host this archive permanently, publically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearestDate(dates, pivot):\n",
    "    return min(dates, key=lambda x: abs(x - pivot))\n",
    "\n",
    "\n",
    "def get_radar_from_aws(site, datetime_t):\n",
    "    \"\"\"\n",
    "    Get the closest volume of NEXRAD data to a particular datetime.\n",
    "    Parameters\n",
    "    ----------\n",
    "    site : string\n",
    "        four letter radar designation \n",
    "    datetime_t : datetime\n",
    "        desired date time\n",
    "    \"\"\"\n",
    "    \n",
    "    #First create the query string for the bucket knowing\n",
    "    #how NOAA and AWS store the data\n",
    "    \n",
    "    my_pref = \"odimh5_archive/\" + site + datetime_t.strftime('/%Y/%m/%d')\n",
    "    #Connect to the bucket\n",
    "    \n",
    "    conn = S3Connection(anon = True)\n",
    "    bucket = conn.get_bucket('roames-wxradar-archive')\n",
    "    \n",
    "    #Get a list of files \n",
    "    \n",
    "    bucket_list = list(bucket.list(prefix = my_pref))\n",
    "    #print(bucket_list)\n",
    "    #we are going to create a list of keys and datetimes to allow easy searching\n",
    "    \n",
    "    keys = []\n",
    "    datetimes = []\n",
    "    \n",
    "    #populate the list\n",
    "    for i in range(len(bucket_list)):\n",
    "        this_str = str(bucket_list[i].key)\n",
    "        if 'h5' in this_str:\n",
    "            endme = this_str[-18:-3]\n",
    "            fmt = '%Y%m%d_%H%M%S' \n",
    "            dt = datetime.strptime(endme, fmt)\n",
    "            datetimes.append(dt)\n",
    "            keys.append(bucket_list[i])\n",
    "            #print(dt)\n",
    "    \n",
    "    #find the closest available radar to your datetime \n",
    "    closest_datetime = nearestDate(datetimes, datetime_t)\n",
    "    index = datetimes.index(closest_datetime)\n",
    "    #print(closest_datetime)\n",
    "    #create a temp file, download radar data to file from S3\n",
    "    #read into a radar object and return\n",
    "    \n",
    "    localfile = tempfile.NamedTemporaryFile()\n",
    "    keys[index].get_contents_to_filename(localfile.name)\n",
    "    radar = pyart.aux_io.read_odim_h5(localfile.name, file_field_names=True) \n",
    "    return radar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok.. now the part that takes some work.. Take a loom here:\n",
    "\n",
    "https://python-twitter.readthedocs.io/en/latest/getting_started.html\n",
    "\n",
    "This gives you instruction on how to populate the json file... \n",
    "\n",
    "Here is an example:\n",
    "`\n",
    "➜  twitterradar git:(tools_init) ✗ more token/PyWeather.json \n",
    "{\"consumer_key\":\"SOMETHING\",\n",
    "\"consumer_secret\":\"SOMETHINGELSE\",\n",
    "\"access_token_key\":\"ANOTHERTHING\",\n",
    "\"access_token_secret\":\"YETANOTHERTHING\"}\n",
    "`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fh = open('/home/meso/aws_key/twitter_key.json')\n",
    "myson = json.load(fh)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api = twitter.Api(consumer_key=myson['consumer_key'],\n",
    "                  consumer_secret=myson['consumer_secret'],\n",
    "                  access_token_key=myson['access_token_key'],\n",
    "                  access_token_secret=myson['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ok.. Now a cool method for tweeting your radar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tweet_my_radar(datetime, radar, tapi, min_lat = None,\n",
    "                  max_lat = None, min_lon = None, \n",
    "                  max_lon = None, fig_sz = None):\n",
    "    \"\"\"\n",
    "    Fetch a radar from S3, plot it and tweet plus statistics.\n",
    "    \n",
    "    Grab a radar from a site and use the Twitter API\n",
    "    to tweet the PPI from the lowest tilt to twitter.\n",
    "    Also tweet the number of gates above two reflectivity\n",
    "    thresholds and the min and max reflectivity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datetime: datetime object\n",
    "        Python datetime object to be passed to the method\n",
    "        to find the nearest radar object from AWS S3 using\n",
    "        boto. \n",
    "    \n",
    "    radar: String\n",
    "        Two number radar code (e.g., 02 Sydney, 66 Brisbane)\n",
    "    \n",
    "    min_lat, max_lat, min_lon, max_lon: floats\n",
    "        bounds for the display\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize = fig_sz)\n",
    "    #setup basemap\n",
    "    ref_m = Basemap(llcrnrlon=min_lon,\n",
    "                llcrnrlat=min_lat,\n",
    "                urcrnrlon=max_lon,\n",
    "                urcrnrlat=max_lat, \n",
    "                projection='tmerc', \n",
    "                resolution = 'f',\n",
    "                epsg = 3857)\n",
    "    \n",
    "    #load background image\n",
    "    im = plt.imread('background.png')\n",
    "    ref_m.imshow(im,zorder = 0,origin='upper')\n",
    "    \n",
    "    my_radar = get_radar_from_aws(radar,b_d )\n",
    "    my_radar.fields['DBZH']['standard_name'] = 'Reflectivity'\n",
    "    my_radar.fields['DBZH']['units'] = 'dBZ'\n",
    "    my_radar.fields['DBZH']['long_name'] = 'Radar Reflectivity Factor'\n",
    "    #Make a display\n",
    "    display = pyart.graph.RadarMapDisplay(my_radar)\n",
    "    #Plot Z from lowest tilt\n",
    "    display.plot_ppi_map('DBZH', sweep = 1, resolution = 'f',\n",
    "                        vmin = -8, vmax = 64, mask_outside = True,\n",
    "                        cmap = pyart.graph.cm.NWSRef,basemap = ref_m,zorder = 1)\n",
    "\n",
    "    #overlay mapping data\n",
    "    im = plt.imread('overlay.png')\n",
    "    ref_m.imshow(im,zorder = 2,origin='upper')\n",
    "    #get a tempfile\n",
    "    localfile = tempfile.NamedTemporaryFile()\n",
    "    #Save to tempfile.. Need png or Twitter gets grumpy \n",
    "    plt.savefig(localfile.name + '.png', dpi = 200)\n",
    "    #Now grab some statistics.. \n",
    "    min_z = my_radar.fields['DBZH']['data'].min()\n",
    "    max_z = my_radar.fields['DBZH']['data'].max()\n",
    "    n_gates_20 = len(np.where(my_radar.fields['DBZH']['data'] > 20.0)[0])\n",
    "    n_gates_40 = len(np.where(my_radar.fields['DBZH']['data'] > 40.0)[0])\n",
    "    \n",
    "    #Format the strings.. TODO: turn into percent\n",
    "    gdata = \"There are {0} gates above 20dBZ and {1} above 40dBZ\".format(n_gates_20, \n",
    "                                                                     n_gates_40)\n",
    "    \n",
    "    #Make the tweet text\n",
    "    mmdata = \"The min Z is {0}dBZ and the max is {1}dBZ\".format(min_z,\n",
    "                                                            max_z)\n",
    "    #And... post it.. yes.. it is that easy!\n",
    "    tapi.PostUpdate( gdata + ' ' + mmdata, \n",
    "              media = localfile.name + '.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_layers(max_lat,min_lat,max_lon,min_lon):\n",
    "    \n",
    "    #generate map bounds\n",
    "    lat_dif   = max_lat-min_lat\n",
    "    lon_dif   = max_lon-min_lon\n",
    "    map_x_sz  = int(500*lon_dif)\n",
    "    map_y_sz  = int(500*lat_dif)\n",
    "\n",
    "    #create overly map\n",
    "    wms = WebMapService('http://services.ga.gov.au/site_7/services/Topographic_Base_Map_WM/MapServer/WMSServer?', version='1.1.1')\n",
    "    img = wms.getmap(layers=['Roads_4','Populated_Places_6'],srs='EPSG:4326',bbox=(min_lon, min_lat, max_lon, max_lat),size=(map_x_sz, map_y_sz),format='image/png',transparent=True)\n",
    "    out = open('overlay.png', 'wb')\n",
    "    out.write(img.read())\n",
    "    out.close()  \n",
    "\n",
    "    #create background map\n",
    "    wms = WebMapService('http://ows.terrestris.de/osm-gray/service?', version='1.1.1')\n",
    "    img = wms.getmap(layers=['TOPO-WMS'],srs='EPSG:4326',bbox=(min_lon, min_lat, max_lon, max_lat),size=(map_x_sz, map_y_sz),format='image/png',transparent=True)\n",
    "    out = open('background.png', 'wb')\n",
    "    out.write(img.read())\n",
    "    out.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TwitterError",
     "evalue": "[{u'message': u'Bad Authentication data.', u'code': 215}]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTwitterError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c99bab94cdd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m tweet_my_radar(b_d, radar, api, min_lat = min_lat,\n\u001b[0;32m     18\u001b[0m                   \u001b[0mmax_lat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_lat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_lon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                   max_lon = max_lon, fig_sz = fig_sz)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-80e1e5a0a696>\u001b[0m in \u001b[0;36mtweet_my_radar\u001b[1;34m(datetime, radar, tapi, min_lat, max_lat, min_lon, max_lon, fig_sz)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m#And... post it.. yes.. it is that easy!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     tapi.PostUpdate( gdata + ' ' + mmdata, \n\u001b[1;32m---> 77\u001b[1;33m               media = localfile.name + '.png')\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/meso/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36mPostUpdate\u001b[1;34m(self, status, media, media_additional_owners, media_category, in_reply_to_status_id, latitude, longitude, place_id, display_coordinates, trim_user, verify_status_length)\u001b[0m\n\u001b[0;32m    992\u001b[0m                     media_ids.append(\n\u001b[0;32m    993\u001b[0m                         self.UploadMediaSimple(media,\n\u001b[1;32m--> 994\u001b[1;33m                                                media_additional_owners))\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'media_ids'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmedia_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/meso/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36mUploadMediaSimple\u001b[1;34m(self, media, additional_owners, media_category)\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RequestUrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ParseAndCheckTwitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/meso/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36m_ParseAndCheckTwitter\u001b[1;34m(self, json_data)\u001b[0m\n\u001b[0;32m   4686\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4687\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_CheckForTwitterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4689\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4690\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"<title>Twitter / Over capacity</title>\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/meso/anaconda2/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36m_CheckForTwitterError\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   4713\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4714\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'errors'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4715\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4717\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_RequestChunkedUpload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTwitterError\u001b[0m: [{u'message': u'Bad Authentication data.', u'code': 215}]"
     ]
    }
   ],
   "source": [
    "#2014 hailstorm for Brisbane\n",
    "\n",
    "fig_sz    = [7,8]\n",
    "base_date = \"20141127_060000\"\n",
    "radar     = \"66\"\n",
    "fmt       = '%Y%m%d_%H%M%S' \n",
    "b_d       = datetime.strptime(base_date, fmt)\n",
    "min_lat   = -28.6\n",
    "max_lat   = -26.8\n",
    "min_lon   = 152.7\n",
    "max_lon   = 153.7  \n",
    "\n",
    "generate_layers(min_lat = min_lat,max_lat = max_lat,\n",
    "                min_lon = min_lon, max_lon = max_lon)\n",
    "\n",
    "#process img\n",
    "tweet_my_radar(b_d, radar, api, min_lat = min_lat,\n",
    "                  max_lat = max_lat, min_lon = min_lon, \n",
    "                  max_lon = max_lon, fig_sz = fig_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://server.arcgisonline.com/ArcGIS/rest/services/World_Topo_Map/MapServer/export?bbox=3648270.83445,-3681909.36342,3826224.46982,-3496818.08908&bboxSR=3825&imageSR=3825&size=750,780&dpi=96&format=png32&f=image\n"
     ]
    }
   ],
   "source": [
    "#now for Brisbane\n",
    "\n",
    "fig_sz    = [7,8]\n",
    "radar   = \"66\"\n",
    "b_d     = datetime.now()\n",
    "min_lat = -28.6\n",
    "max_lat = -26.8\n",
    "min_lon = 152.7\n",
    "max_lon = 153.7\n",
    "\n",
    "generate_layers(min_lat = min_lat,max_lat = max_lat,\n",
    "                min_lon = min_lon, max_lon = max_lon,)\n",
    "\n",
    "#process img\n",
    "tweet_my_radar(b_d, radar, api, min_lat = min_lat,\n",
    "                  max_lat = max_lat, min_lon = min_lon, \n",
    "                  max_lon = max_lon, fig_sz = fig_sz)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
